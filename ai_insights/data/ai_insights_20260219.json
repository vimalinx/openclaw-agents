{
  "report_date": "2026年02月19日",
  "week_number": 8,
  "papers": [
    {
      "title": "Policy Compiler for Secure Agentic Systems",
      "authors": [
        "Nils Palumbo",
        "Sarthak Choudhary",
        "Jihye Choi",
        "Prasad Chalasani",
        "等"
      ],
      "summary": "LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement. Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. ...",
      "link": "https://arxiv.org/abs/2602.16708v1",
      "category": "cs.AI",
      "published": "2026-02-18T18:57:12Z"
    },
    {
      "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology",
      "authors": [
        "Shen Zhou Hong",
        "Alex Kleinman",
        "Alyssa Mathiowetz",
        "Adam Howes",
        "等"
      ],
      "summary": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics work...",
      "link": "https://arxiv.org/abs/2602.16703v1",
      "category": "cs.AI",
      "published": "2026-02-18T18:51:28Z"
    },
    {
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "summary": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lo...",
      "link": "https://arxiv.org/abs/2602.16699v1",
      "category": "cs.AI",
      "published": "2026-02-18T18:46:14Z"
    },
    {
      "title": "Knowledge-Embedded Latent Projection for Robust Representation Learning",
      "authors": [
        "Weijing Tang",
        "Ming Yuan",
        "Zongqi Xia",
        "Tianxi Cai"
      ],
      "summary": "Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extrem...",
      "link": "https://arxiv.org/abs/2602.16709v1",
      "category": "cs.LG",
      "published": "2026-02-18T18:58:16Z"
    },
    {
      "title": "Causality is Key for Interpretability Claims to Generalise",
      "authors": [
        "Shruti Joshi",
        "Aaron Mueller",
        "David Klindt",
        "Wieland Brendel",
        "等"
      ],
      "summary": "Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies w...",
      "link": "https://arxiv.org/abs/2602.16698v1",
      "category": "cs.LG",
      "published": "2026-02-18T18:45:04Z"
    },
    {
      "title": "Protecting the Undeleted in Machine Unlearning",
      "authors": [
        "Aloni Cohen",
        "Refael Kohen",
        "Kobbi Nissim",
        "Uri Stemmer"
      ],
      "summary": "Machine unlearning aims to remove specific data points from a trained model, often striving to emulate \"perfect retraining\", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechani...",
      "link": "https://arxiv.org/abs/2602.16697v1",
      "category": "cs.LG",
      "published": "2026-02-18T18:44:21Z"
    },
    {
      "title": "Reinforced Fast Weights with Next-Sequence Prediction",
      "authors": [
        "Hee Seung Hwang",
        "Xindi Wu",
        "Sanghyuk Chun",
        "Olga Russakovsky"
      ],
      "summary": "Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, lear...",
      "link": "https://arxiv.org/abs/2602.16704v1",
      "category": "cs.CL",
      "published": "2026-02-18T18:53:18Z"
    },
    {
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "summary": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lo...",
      "link": "https://arxiv.org/abs/2602.16699v1",
      "category": "cs.CL",
      "published": "2026-02-18T18:46:14Z"
    },
    {
      "title": "Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens",
      "authors": [
        "Potsawee Manakul",
        "Woody Haosheng Gan",
        "Martijn Bartelds",
        "Guangzhi Sun",
        "等"
      ],
      "summary": "Current audio language models are predominantly text-first, either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, limiting general audio modeling. This paper presents a systematic empirical study of native audio foundation models that apply next-token prediction to audio at scale, jointly modeling semantic content, acoustic details, and text to support both general audio generation and cross-modal capabilities. We provide comprehensive empirical insights for b...",
      "link": "https://arxiv.org/abs/2602.16687v1",
      "category": "cs.CL",
      "published": "2026-02-18T18:32:46Z"
    },
    {
      "title": "TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos",
      "authors": [
        "Namitha Padmanabhan",
        "Matthew Gwilliam",
        "Abhinav Shrivastava"
      ],
      "summary": "Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamen...",
      "link": "https://arxiv.org/abs/2602.16711v1",
      "category": "cs.CV",
      "published": "2026-02-18T18:59:55Z"
    },
    {
      "title": "Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation",
      "authors": [
        "Runpei Dong",
        "Ziyan Li",
        "Xialin He",
        "Saurabh Gupta"
      ],
      "summary": "Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generali...",
      "link": "https://arxiv.org/abs/2602.16705v1",
      "category": "cs.CV",
      "published": "2026-02-18T18:55:02Z"
    },
    {
      "title": "Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning",
      "authors": [
        "Mingjia Shi",
        "Yinhan He",
        "Yaochen Zhu",
        "Jundong Li"
      ],
      "summary": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominate...",
      "link": "https://arxiv.org/abs/2602.16702v1",
      "category": "cs.CV",
      "published": "2026-02-18T18:49:56Z"
    },
    {
      "title": "End-user validation of BRIGHT with custom-developed graphical user interface applied to cervical cancer brachytherapy",
      "authors": [
        "Leah R. M. Dickhoff",
        "Ellen M. Kerkhof",
        "Heloisa H. Deuzeman",
        "Laura A. Velema",
        "等"
      ],
      "summary": "Multi-objective optimisation using BRIGHT has proven insightful and effective in prostate cancer brachytherapy treatment planning. BRachytherapy via artificially Intelligent GOMEA-Heuristic based Treatment planning (BRIGHT) generates multiple treatment plans, each with a different trade-off between tumour coverage and organs-at-risk sparing. BRIGHT was recently extended to cervical cancer brachytherapy. In this study, we present a novel, custom-developed graphical user interface (GUI) that enabl...",
      "link": "https://arxiv.org/abs/2602.16321v1",
      "category": "cs.NE",
      "published": "2026-02-18T10:01:21Z"
    },
    {
      "title": "Evolutionary Context Search for Automated Skill Acquisition",
      "authors": [
        "Qi Sun",
        "Stefan Nielsen",
        "Rio Yokota",
        "Yujin Tang"
      ],
      "summary": "Large Language Models cannot reliably acquire new knowledge post-deployment -- even when relevant text resources exist, models fail to transform them into actionable knowledge without retraining. Retrieval-Augmented Generation attempts to bridge this gap by surfacing relevant documents at inference time, yet similarity-based retrieval often fails to identify context that actually improves task performance. We introduce Evolutionary Context Search (ECS), an evolutionary method that searches conte...",
      "link": "https://arxiv.org/abs/2602.16113v1",
      "category": "cs.NE",
      "published": "2026-02-18T00:47:02Z"
    },
    {
      "title": "Heuristic Search as Language-Guided Program Optimization",
      "authors": [
        "Mingxin Yu",
        "Ruixiao Yang",
        "Chuchu Fan"
      ],
      "summary": "Large Language Models (LLMs) have advanced Automated Heuristic Design (AHD) in combinatorial optimization (CO) in the past few years. However, existing discovery pipelines often require extensive manual trial-and-error or reliance on domain expertise to adapt to new or complex problems. This stems from tightly coupled internal mechanisms that limit systematic improvement of the LLM-driven design process. To address this challenge, we propose a structured framework for LLM-driven AHD that explici...",
      "link": "https://arxiv.org/abs/2602.16038v1",
      "category": "cs.NE",
      "published": "2026-02-17T21:45:42Z"
    }
  ],
  "hn_discussions": [
    {
      "title": "Show HN: Kore – local AI memory layer with Ebbinghaus forgetting curve",
      "url": "https://github.com/auriti-web-design/kore-memory",
      "score": 1,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Show HN: Social Cookie Jar – Social media automation for AI agents",
      "url": "https://github.com/Artifact-Virtual/social-cookie-jar",
      "score": 1,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Phill CLI matches GPT-5.3-Codex on EVMbench audits (71% recall, 100% precision)",
      "url": "https://github.com/ayjays132/phill-cli",
      "score": 1,
      "comments": 1,
      "time": "2026-02-19"
    },
    {
      "title": "Show HN: Onairos SDK– Unified Context API, unlocking cross platform user history",
      "url": "https://onairos.io",
      "score": 1,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Have we entered a new age of AI-enabled scientific discovery?",
      "url": "https://www.sciencenews.org/article/ai-enabled-science-discovery-insight",
      "score": 1,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Show HN: EasyCheck – lightweight compliance automation for small teams",
      "url": "https://easycheck.dk/en",
      "score": 1,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Does open source have an AI slop problem? [video]",
      "url": "https://www.youtube.com/watch?v=5uLHMdsjXBQ",
      "score": 3,
      "comments": 0,
      "time": "2026-02-19"
    },
    {
      "title": "Show HN: Potatometer – Check how visible your website is to AI search (GEO)",
      "url": "https://potatometer.com/",
      "score": 3,
      "comments": 3,
      "time": "2026-02-19"
    }
  ],
  "github_trending": [
    {
      "name": "autogen",
      "author": "microsoft",
      "description": "Enable next-gen LLM applications. Converse, collaborate, and code with agents.",
      "stars": 28000,
      "url": "https://github.com/microsoft/autogen",
      "tags": [
        "多智能体",
        "LLM",
        "框架"
      ]
    },
    {
      "name": "langchain",
      "author": "langchain-ai",
      "description": "Building applications with LLMs through composability",
      "stars": 76000,
      "url": "https://github.com/langchain-ai/langchain",
      "tags": [
        "LLM",
        "RAG",
        "框架"
      ]
    },
    {
      "name": "vllm",
      "author": "vllm-project",
      "description": "A high-throughput and memory-efficient inference and serving engine for LLMs",
      "stars": 21000,
      "url": "https://github.com/vllm-project/vllm",
      "tags": [
        "推理加速",
        "LLM",
        "部署"
      ]
    },
    {
      "name": "open-interpreter",
      "author": "OpenInterpreter",
      "description": "Open Interpreter lets LLMs run code (Python, JS, Shell, etc.) on your computer",
      "stars": 46000,
      "url": "https://github.com/OpenInterpreter/open-interpreter",
      "tags": [
        "代码执行",
        "AI助手",
        "工具"
      ]
    },
    {
      "name": "ComfyUI",
      "author": "comfyanonymous",
      "description": "A powerful and modular stable diffusion GUI",
      "stars": 39000,
      "url": "https://github.com/comfyanonymous/ComfyUI",
      "tags": [
        "图像生成",
        "GUI",
        "扩散模型"
      ]
    }
  ]
}