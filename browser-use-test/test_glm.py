#!/usr/bin/env python3
"""
æµ‹è¯•ç”¨ GLM-4 é…ç½® browser-use
"""
import asyncio
from browser_use import Agent, Browser
from langchain_openai import ChatOpenAI

async def test_with_glm():
    """ä½¿ç”¨ GLM-4 æµ‹è¯•æµè§ˆå™¨è‡ªåŠ¨åŒ–"""
    print("ğŸº Wilson ä½¿ç”¨ GLM-4 æµ‹è¯•...")

    browser = Browser()

    # é…ç½® GLM-4ï¼ˆæ™ºè°± AIï¼‰
    llm = ChatOpenAI(
        model="glm-4-flash",  # ä½¿ç”¨å¿«é€Ÿç‰ˆæœ¬
        base_url="https://open.bigmodel.cn/api/coding/paas/v4",
        api_key="9ac45d2e82df427dbef6467567e81753.2kF0sITkGWI2f54T",
        temperature=0.0,
    )

    agent = Agent(
        task="è®¿é—® https://www.example.com å¹¶å‘Šè¯‰æˆ‘è¿™ä¸ªé¡µé¢çš„æ ‡é¢˜å’Œä¸»è¦å†…å®¹",
        llm=llm,
        browser=browser,
    )

    try:
        result = await agent.run()
        print("\nâœ… æµ‹è¯•æˆåŠŸï¼")
        print(f"ç»“æœ: {result}")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ å¯èƒ½éœ€è¦ï¼š")
        print("1. å®Œæ•´çš„ API keyï¼ˆä» OpenClaw é…ç½®ä¸­è·å–ï¼‰")
        print("2. æˆ–è€…æ”¹ç”¨å…¶ä»– LLMï¼ˆOpenAIã€æœ¬åœ° Ollama ç­‰ï¼‰")

if __name__ == "__main__":
    asyncio.run(test_with_glm())
