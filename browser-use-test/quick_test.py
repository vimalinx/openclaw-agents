#!/usr/bin/env python3
"""å¿«é€Ÿæµ‹è¯•ï¼šç”¨ GLM-4 æ§åˆ¶ browser-use"""
import asyncio
from dotenv import load_dotenv
from browser_use import Agent, Browser
from browser_use.llm.openai.chat import ChatOpenAI

load_dotenv()

async def test():
    print("ğŸº Wilson ç”¨ GLM-4 æµ‹è¯• browser-use...")

    browser = Browser()

    # ä½¿ç”¨ browser-use çš„ ChatOpenAIï¼ˆæ”¯æŒè‡ªå®šä¹‰ base_urlï¼‰
    llm = ChatOpenAI(
        model="glm-4.7",
        base_url="https://open.bigmodel.cn/api/coding/paas/v4",
        api_key="9ac45d2e82df427dbef6467567e81753.2kF0sITkGWI2f54T",
        temperature=0.0,
    )

    # ç®€å•ä»»åŠ¡
    agent = Agent(
        task="è®¿é—® https://www.example.com å¹¶å‘Šè¯‰æˆ‘è¿™ä¸ªé¡µé¢çš„æ ‡é¢˜",
        llm=llm,
        browser=browser,
    )

    try:
        result = await agent.run()
        print("\nâœ… æˆåŠŸï¼")
        print(f"LLM ç†è§£çš„ç»“æœ:\n{result}")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test())
