#!/usr/bin/env python3
"""æµ‹è¯• GLM-4.7 æ¨ç†æ¨¡å‹ï¼ˆå¸¦ reasoningï¼‰"""
import asyncio
from browser_use import Agent, Browser
from browser_use.llm.openai.chat import ChatOpenAI

async def test_with_reasoning():
    """æµ‹è¯• GLM-4.7 æ¨ç†æ¨¡å‹"""
    print("ğŸº Wilson æµ‹è¯• GLM-4.7 æ¨ç†æ¨¡å‹...")

    browser = Browser()

    # GLM-4.7 æ˜¯æ¨ç†æ¨¡å‹ï¼Œéœ€è¦ç‰¹æ®Šé…ç½®
    llm = ChatOpenAI(
        model="glm-4.7",
        base_url="https://open.bigmodel.cn/api/coding/paas/v4",
        api_key="9ac45d2e82df427dbef6467567e81753.2kF0sITkGWI2f54T",
        temperature=0.0,
    )

    # æ›´ç®€å•çš„ä»»åŠ¡
    agent = Agent(
        task="è®¿é—® https://www.example.comï¼Œæ‰¾åˆ°é¡µé¢æ ‡é¢˜ï¼Œç„¶åä½¿ç”¨ done åŠ¨ä½œç»“æŸ",
        llm=llm,
        browser=browser,
        max_actions_per_step=1,  # é™åˆ¶æ¯æ¬¡åªæœ‰ä¸€ä¸ªåŠ¨ä½œ
        use_thinking=True,  # å¯ç”¨æ€è€ƒæ¨¡å¼
    )

    try:
        result = await agent.run()
        print("\nâœ… æˆåŠŸï¼")
        print(f"ç»“æœ: {result}")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_with_reasoning())
